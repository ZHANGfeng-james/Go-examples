前一章我们介绍了一些使用 goroutine 和 channel 这样**直接而自然的方式**来==实现并发的方法==，然而这样做我们实际上回避了在写并发代码时必须处理的一些重要而且细微的问题。

在本章中，我们会细致地了解并发机制。尤其是==在多 goroutine 之间的共享变量==，**并发问题的分析手段**，以及**解决这些问题的基本模式**。最后我们会解释 goroutine 和操作系统线程之间的技术上的一些区别。

## 竞争条件

在一个**线性的程序**（只有一个 goroutine ）中，**程序的执行顺序只由程序的逻辑来决定**。例如，我们有一段语句序列，第一个在第二个之前，以此类推。在有两个或多个 goroutine 的程序中，**每一个 goroutine 内的语句也是按照既定的顺序去执行的**，但是一般情况下我们==没法去知道==分别位于两个 goroutine 的事件 x 和 y 的执行顺序，x 是在 y 之前还是之后还是同事发生是没法判断的。当我们没有办法自信地确认一个事件是在另一个事件的前面或者后面发生的话，就说明 x 和 y 这两个事件是==并发的==。

考虑一下，一个函数在线性程序中可以正确地工作。如果有并发的情况下，这个函数依然可以正确地工作的话，那么我们就说这个函数是并发安全的，并发安全的函数不需要额外的同步工作。我们可以把这个概念概括为一个特定类型的一些方法和操作函数，对于某个类型来说，如果其所有可访问的方法和操作都是并发安全的话，那么该类型便是并发安全的。

**在一个程序中有非并发安全的类型的情况下，我们依然可以使这个程序并发安全**。确实，并发安全的类型是例外，而不是规则，所以**只有当文档中明确地说明了其是并发安全的情况下，你才可以并发地去访问它**。我们会避免并发访问大多数的类型，无论是将变量局限在单一的一个 goroutine 内，还是用互斥条件维持更高级别的不变性，都是为了这个目的。我们会在本章中说明这些术语。

相反，**包级别的导出函数一般情况下都是并发安全的**。由于 package 级的变量**没法被限制在单一的 goroutine**，所以修改这些变量“必须”使用互斥条件。

一个函数在并发调用时没法工作的原因太多了，比如死锁（deadlock）、活锁（livelock）和饿死（resource starvation）。我们没空去讨论所有的问题，==这里我们只聚焦在竞争条件上==。

==竞争条件指的是程序在多个 goroutine 交叉执行操作时，没有给出正确的结果==。竞争条件是很恶劣的一种场景，因为这种问题会一直潜伏在你的程序里，然后在非常少见的时候蹦出来，或许只是会**在很大的负载时**才会发生，又或许是会**在使用了某一个编译器、某一种平台或者某一种架构的时候**才会出现。这些使得==竞争条件带来的问题非常难以复现而且难以分析诊断==。

传统上经常用经济损失来为竞争条件做比喻，所以我们来看一个简单的银行账户程序：

~~~go
var balance int
func Deposit(amount int) {
    balance = balance + amount
}
func Balance() int {
    return balance
}
~~~

当然我们也可以把 Deposit 存款函数写成 `balance += amount`，这种形式也是等价的，不过长一些的形式解释起来更方便一些。

对于这个简单的程序而言，我们一眼就能看出，以任意顺序调用函数 Deposit 和 Balance 都会得到正确的结果。也就是说，Balance 函数会给出之前的所有存入的额度之和。然而，当我们并发地而不是顺序地调用这些函数的话，Balance 就再也没办法保证结果正确了。考虑以下下面的两个 goroutine，其代表了**一个银行联合账户的两笔交易**：

~~~go 
go func() {
    bank.Deposit(200)                    // A1
    fmt.Println("=", bank.Balance())     // A2
}()

go bank.Deposit(100)                     // B
~~~

Alice 存了 ￥200，然后检查她的余额，同时 Bob 存了￥100。因为 A1 和 A2 是和 B 并发执行的，我们没法预测他们发生的先后顺序。直观地来看的话，我们会认为其执行顺序只有三种可能性：Alice 先，Bob 先以及 Alice/Bob/Alice 交替执行。下面的表格会展示经过每一步骤后 balance 变量的值：

~~~go
Alice first        Bob first        Alice/Bob/Alice
          0                0                      0
  A1    200        B     100             A1     200
  A2 "= 200"       A1    300             B      300
  B     300        A2 "= 300"            A2  "= 300"
~~~

所有情况下最终的余额都是 ￥300。唯一的变数是 Alice 的余额单是否包含了 Bob 的交易，不过无论怎么着客户都不会在意。

但是事实是上面的直觉推断是错误的。第四种可能的结果是事实存在的，这种情况下 Bob 的存款会在 Alice 存款操作中间，在余额被读到（balance + amount） 之后，在余额被更新之前（balance = ...），这样会导致 Bob 的交易丢失。而这是因为 Alice 的存款操作 A1 实际上是两个操作的一个序列，读取然后写；可以称之为 `A1r` 和 `A1w`。下面是交叉时产生的问题：

~~~go
Data race
0
A1r      0     ... = balance + amount --> 值为 200
B      100
A1w    200     balance = ...
A2  "= 200"
~~~

在 `A1r` 之后，`balance + amount` 会被计算为 200，所以这是 `A1w` 会写入的值，并不受其他存款操作的干预。最终的余额是￥200。

==这个程序包含了一个特定的竞争条件，叫做数据竞争==。无论任何时候，只要有两个 goroutine 并发访问同一个变量，且至少其中的一个是写操作的时候就会发生数据竞争。

**如果数据竞争的对象是一个比机器字更大的类型时，事情就变得更麻烦了**，比如 `interface`，string 或者 slice 类型都是如此。下面的代码会并发地更新两个不同长度的 slice：

~~~go
var x []int
go func() {
    x = make([]int, 10)
}()

go func() {
    x = make([]int, 1000000)
}()

x[999999] = 1
~~~

最后一个语句中的 x 的值是**未定义的**；其可能是 nil，或者也可能是一个长度为 10 的 slice，也可能是一个长度为 1,000,000 的 slice。但是回忆一下 slice 的三个组成部分：指针、长度和容量。如果指针是从第一个 make 调用来，而长度从第二个 make 来，x 就变成了一个混合体，一个自称长度为 1,000,000 但实际上内存只有 10 个元素的 slice。这样导致的结果是存储 999,999 元素的位置会碰撞一个遥远的内存位置，这种情况下难以对值进行预测，而且 debug 也会变成噩梦。这种语义雷区被称为未定义行为，对 C 程序员来说应该很熟悉；幸运的是在 Go 语言里造成的麻烦要比 C 里小得多。

尽管并发程序的概念让我们知道==并发并不是简单的语句交叉执行==。我们将会在后续节中看到，数据竞争可能会有奇怪的结果。许多程序员，甚至一些非常聪明的人也还是会偶尔提出一些理由来允许数据竞争，比如：“互斥条件代价太高”，“这个逻辑知识用来做 logging”，“我不介意丢失一些消息”等等。因为在他们的编译器或者平台上很少遇到问题，可能给了他们错误的信心。一个好经验法则是根本就没有所谓的良性数据竞争。所以**我们一定要避免数据竞争，那么在我们的程序中要如何做到呢？**

我们来重复一下数据竞争的定义，因为实在太重要了：==数据竞争会在两个以上的 goroutine 并发访问相同的变量且至少其中一个为写操作时发生==。根据上述定义，有 3 种方式可以避免数据竞争：

第一种：**不要去写变量**。考虑下面的 map，会被“懒”填充，也就是说在每个 key 被第一次请求到的时候才会去填值。如果 Icon 是被顺序调用的话，这个程序会工作很正常，但如果 Icon 被并发调用，那么对于这个 map 来说就会存在数据竞争：

~~~go
var icons = make(map[string]image.Image)
func loadIcon(name string) image.Image
// NOTE: not concurrency-safe
func Icon(name string) image.Image {
    // SING: icons 的数据竞争
    icon, ok := icons[name]
    if !ok {
        icon = loadIcon(name)
        icons[name] = icon
    }
    return icon
}
~~~

反之，如果我们在创建 goroutine 之前的初始化阶段，就初始化了 map 中的所有条目并且再也不去修改它们，那么任意数量的 goroutine 并发访问 Icon 都是安全的，因为每一个 goroutine 都只是去读取而已：

~~~go
var icons = map[string]image.Image {
    "spades.png": load("spades.png"),
    "hearts.png":   loadIcon("hearts.png"),
    "diamonds.png": loadIcon("diamonds.png"),
    "clubs.png":    loadIcon("clubs.png"),
}

func Icon(name string) image.Image {
    return icons[name]
}
~~~

上面的例子里 icons 变量在包初始化阶段就已经被赋值了，包的初始化是在程序 main 函数开始执行之前就完成了的。只要初始化完成了，icons 就再也不会被修改。数据结构如果从不被修改或是不变化则是并发安全的，无需进行同步。不过显然，如果 update 操作是必要的，我们就没法用这种方法，比如说银行账户。

第二种：**避免从多个 goroutine 访问变量**（**访问变量，可分为：读变量和写变量**）。这也是前一章中大多数程序所采用的方法。例如前面的并发 web 爬虫的 main goroutine 是唯一一个能够访问 seen map 的 goroutine，而聊天服务器中的 broadcaster goroutine 是唯一一个能够访问 clients map 的 goroutine。这些变量都被限定在了一个单独的 goroutine 中。

由于其他的 goroutine 不能直接访问变量，它们智能使用一个 Channel 来发送请求给指定的 goroutine 来查询更新变量。**这也就是 Go 的口头禅“不要使用共享数据来通信；使用通信来共享数据”**。一个提供对一个指定的变量通过 channel 来请求的 goroutine 叫做这个变量的 monitor goroutine。例如 broadcaster goroutine 会监控 clients map 的全部访问。

下面是一个重写的银行的例子，这个例子中的 balance 变量被限制在了 monitor goroutine 中，名为 teller：

~~~go
package bank

import "fmt"

var deposits = make(chan int)
var balances = make(chan int)

// Deposit is a action for deposit, it is used out of package
func Deposit(amount int) {
	deposits <- amount
}

// Balance means "get balance", it is used out of package
func Balance() int {
	return <-balances
}

func teller() {
	var balance int // balance is confined to teller goroutine
	for {
		select {
		case amount := <-deposits:
			balance += amount
		case balances <- balance:
			// do nothing
		}
	}
}

func init() {
	go teller() // start the monitor goroutine
}
~~~

对应的示例程序：

~~~go
package main

import (
	"fmt"
	"sync"

	"test.go/bank"
)

func main() {
	var wg sync.WaitGroup
	for index := 0; index < 10000; index++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for index := 0; index < 1; index++ {
				bank.Deposit(1)
			}
		}()
	}

	wg.Wait()
	balance := bank.Balance()
	fmt.Println(balance)
}
~~~

上述的调用始终都能获得正确的输出结果！

即使当一个变量无法在其整个生命周期内被绑定到一个独立的 goroutine，绑定依然是并发问题的一个解决方案。例如一条流水线上的 goroutine 之间共享变量是很普遍的行为，在这两者间会通过 channel 来传输地址信息。如果流水线的每一个阶段都能够避免在将变量传送到下一阶段后再去访问它，那么对这个变量的所有访问就是线性的。其效果是变量会被绑定到流水线的一个阶段，传送完之后被绑定到下一个，以此类推。这种规则有时被称为==串行绑定==。

下面例子中，Cakes 会被严格地顺序访问，显示 baker goroutine，然后是 icer goroutine：

~~~go
type Cake struct{
    state string
}

func baker(cooked chan<- *Cake) {
    for {
        cake := new(Cake)
        cake.state = "cooked"
        cooked <- cake // baker never touches this cake again
    }
}

func icer(iced chan<- *Cake, cooked <-chan *Cake) {
    for cake := range cooked {
        cake.state = "iced"
        iced <- cake // icer never touches this cake again
    }
}
~~~

第三种避免数据竞争的方法是允许很多 goroutine 去==访问==变量（**访问变量，可分为：读变量和写变量**），**但是在同一时刻最多只有一个 goroutine 在访问**。这种方式被称为“互斥”。

## sync.Mutex 互斥锁

在“并发 Web 爬虫”示例程序中，我们使用了一个 buffered channel 作为一个计数信号量，来保证最多只有 20 个 goroutine 会同时执行 HTTP 请求。同理，我们可以**用一个容量只有 1 的 channel 来保证最多只有一个 goroutine 在同一时刻访问一个共享变量**。==一个只能为 1 和 0 的信号量叫做二元信号量（binary semaphore）==。

~~~go
var (
    sema = make(chan struct{}, 1) // a binary semaphore guarding balance
    balance int
)

func Deposit(amount int) {
    sema <- struct{}{}            // acquire token
    balance = balance + amount
    <-sema                        // release token
}

func Balance() int {
    sema <- struct{}{}            // acquire token
    b := balance
    <-sema                        // release token
    return b
}
~~~

对于 `sema = make(chan struct{}, 1)` 和 `sema = make(chan struct{})` 的区别在于：**后者执行了 `chan<-` 会阻塞 goroutine，直到执行了 `<-chan` 后 goroutine 才会继续执行；但是对于前者执行了 `chan<-` 不会阻塞，goroutine 会继续执行，但是在此执行 `chan<-` 时，`chan` 因为只有 1 个缓冲区，则会阻塞 goroutine，直到 `chan` 排空**。

**这种互斥很实用，而且被 sync 包里的 Mutex 类型直接支持**。它的 Lock 方法能够获取到 token（这里叫锁），并且 Unlock 方法会释放这个 token：

~~~go
package bank

import "sync"

var (
	mu      sync.Mutex
	balance int
)

// Deposit is a action for deposit, it is used out of package
func Deposit(amount int) {
	mu.Lock()
	balance = balance + amount
	mu.Unlock()
}

// Balance means "get balance", it is used out of package
func Balance() int {
	mu.Lock()
	b := balance
	mu.Unlock()
	return b
}
~~~

每次一个 goroutine 访问 bank 变量时（这里只有 balance 余额变量），它都会调用 mutex 的 Lock 方法来==获取一个互斥锁==。如果其他的 goroutine 已经获得了这个锁的话，这个操作会被阻塞直到其他 goroutine 调用了 `Unlock` **使该锁变回可用状态**。mutex 会保护共享变量。**惯例来说，被 mutex 所保护的变量是在 mutex 变量声明之后立刻声明的**。如果你的做法和惯例不符，确保在文档里对你的做法进行说明。

在 `Lock` 和 `Unlock` 之间的代码段中的内容 `goroutine` 可以**随便读取或者修改**，这个代码段叫做**临界区**。锁的持有者在其他 goroutine 获取该锁之前需要调用 `Unlock`。goroutine 在结束后释放锁是必要的，无论以哪条路径通过函数都需要释放，即使是在错误路径中，也要记得释放。

上面  bank 程序例证了==一种通用的并发模式==。一系列的导出函数封装了一个或多个变量，那么访问这些变量唯一的方式就是通过这些函数来做（==或者方法，对于一个对象的变量来说==）。每一个函数在一开始就获取互斥锁并在最后释放锁，从而保证共享变量不会被并发访问。这种函数、互斥锁和变量的编排叫做监控 monitor。

由于在存款和查询余额函数中的临界区代码这么短——只有一行，没有分支调用——在代码最后去调用 Unlock 就显得更为直截了当。在更复杂的临界区的应用中，尤其是必须要尽早处理错误并返回的情况下，就很难去（靠人）判断对 `Lock` 和 `Unlock` 的调用是在所有路径中都能够严格配对的了。Go 语言里的 defer 键值就是这种情况下的救星：我们用 `defer` 来调用 `Unlock`，临界区会隐式地延伸到函数作用域的最后，这样我们就从“总要记得在函数返回之后或者发生错误返回时调用一次 Unlock”这种状态中获得了解法。Go 会自动帮我们完成这些事情：

~~~go
func Balance() int {
    mu.Lock()
    defer mu.Unlock()
    return balance
}
~~~

上面的例子里 Unlock 会在 return 语句读取完 balance 的值之后执行，所以 Balance 函数是并发安全的。这带来了另外一个好处：我们再也不需要一个本地变量 b 了。

此外，一个 deferred Unlokc 即使在临界区发生 panic 时依然会执行，这对于用 recover 来恢复的程序来说是很重要的。defer 调用只会比显式地调用 Unlock 成本高那么一点点你，不过却在很大程度上保证了代码的整洁性。大多数情况下对于并发程序来说，代码的整洁性比过度的优化更重要。如果可能的话尽量使用 defer 来将临界区扩展到函数的结束。

考虑以下下面的 Withdraw 函数，成功的时候，它会正确地减掉余额并返回 true。但如果银行记录资金对交易来说不足，那么取款就会恢复余额，并返回 false：

~~~go
// NOTE: not atomic!
func Withdraw(amount int) bool {
    Deposit(-amount)
    if Balance() < 0 {
        Deposit(amount)
        return false
    }
    return true
}
~~~

函数终于给出了正确的结果，但是还有一点讨厌的副作用。当过多的取款操作同时执行时，balance 可能会瞬时被减到 0 以下。这可能**会引起一些并发的取款被不合逻辑地拒绝**。所以如果 Bob 尝试买一辆 sports car 时，Alice 可能就没有办法为她的早餐咖啡付款了。这里的问题是==取款不是一个原子操作==：它包含了三个步骤，**每一步都需要去获取并释放互斥锁，但任何一次锁都不会锁上整个取款流程**。

理想情况下，取款应该只在整个操作中获得一次互斥锁。下面这样的尝试==是错误的==：

~~~go
// NOTE: incorrect!
func Withdraw(amount int) bool {
    mu.Lock()
    defer mu.Unlock()
    
    Deposit(-amount)
    if Balance() < 0 {
        Deposit(amount)
        return false
    }
    return true
}
~~~

上面这个例子中，Deposit 会调用 mu.Lock() 第二次去获取互斥锁，但因为 mutex 已经锁上了，而无法被重入（Go 语言里没有重入锁，关于重入锁的概念，可参考 Java）。也就是说没法对一个已经上锁的 mutex 来再次上锁。这会导致程序死锁，没法继续执行下去，Withdraw 会永远阻塞下去。

关于 **Go 的 mutex 不能重入**这一点我们有很充分的理由。mutex 的目的是确保共享变量在程序执行时的关键点上能够保证==不变性==。==不变性的其中之一是“没有 goroutine 访问共享变量”==，但实际上这里对于 mutex 保护的变量来说，不变性还包括其他方面。当一个 goroutine 获得了一个互斥锁时，它会断定这种不变性能够被保持。在其获取并保持锁期间，可能会去更新共享变量，这样不变性只是短暂地被破坏。然而当其释放锁之后，它必须保证不变性已经恢复原样。尽管一个可以重入的 mutex 也可以保证没有其他的 goroutine 在访问共享变量，但这种方式没法保证这些变量**额外的不变性**。

==一个通用的解决方案是将一个函数分离为多个函数==，比如我们把 Deposit 分离成两个：一个不导出的函数 depoist，这个函数**假设**锁总是会**被保持**并去做实际的操作，另一个是导出的函数 Deposit，这个函数会调用 deposit，但在调用前会先去获取锁。同理我们可以将 Withdraw 也表示成这种形式：

~~~go
// This function requires that the lock be held
func deposit(amount int) {
    balance += amount
}

func WithDraw(amount int) bool {
    mu.Lock()
    defer mu.Unlock()
    
    deposit(-amount)
    if balance < 0 {
        deposit(amount)
        retrun false
    }
    return true
}

func Deposit(amount int) {
    mu.Lock()
    defer mu.Unlock()
    deposit(amount)
}

func Balance() int {
    mu.Lock()
    defer mu.Unlock()
    return balance
}
~~~

当然，这里的存款 deposit 函数很小，实际上取款 Withdraw 函数不需要理会对它的调用，尽管如此，这里的表达还是表明了规则。

==封装，用限制一个程序中的意外交互的方式，可以使我们获得数据结构的不变性==。因为某种原因，封装还帮我们获得了并发的不变性。当你使用 mutex 时，确保 mutex 和其保护的变量没有被导出（在 Go 语言中是小写，且不要别大写字母开头的函数调用！），无论这些变量是包级别的变量还是一个 struct 字段。

## sync.RWMutex 读写锁

在 ￥100 的存款消失时不做记录多少还是会让我们有些恐慌，Bob 写了一个程序，每秒运行几百次来检查他的银行余额。他会在家，在工作中，甚至会在它的手机上来运行这个程序。银行注意到**这些陡增的流量使得存款和取款有了延时**，**因为所有的余额查询请求是顺序执行的**，这样会互斥地获得锁，并且会暂时阻止其他的 goroutine 运行。

由于 Balance 函数只需要读取变量的状态，所以我们同时让多个 Balance 调用并发运行是安全的，只要在运行的时候没有存款或者取款操作就行。在这种场景下我们需要**一种特殊类型的锁**，==其允许多个只读操作并行执行==，但写操作会完全互斥。**这种锁叫做“多读单写”锁**（multiple readers, single writer lock），Go 语言提供的这样的锁是 `sync.RWMutex`：

~~~go
package bank

import (
	"fmt"
	"sync"
)

var (
	mu      sync.Mutex
	muOther sync.RWMutex
	balance int
)

// This function requires that the lock be held
func deposit(amount int) {
	balance += amount
}

// WithDraw function lets balance down
func WithDraw(amount int) bool {
	mu.Lock()
	defer mu.Unlock()

	deposit(-amount)
	if balance < 0 {
		deposit(amount)
		return false
	}
	return true
}

// Deposit is a action for deposit, it is used out of package
func Deposit(amount int) {
	mu.Lock()
	defer mu.Unlock()
	deposit(amount)
}

// Balance is a function for getting balance
func Balance() int {
	muOther.RLock()
	defer muOther.RUnlock()
	return balance
}
~~~

`Balance` 函数现在调用 `RLock` 和 `RUnlock` 方法来获取和释放一个读取或者共享锁。Deposit 函数没有变化，会调用 mu.Lock 和 mu.Unlock 方法来获取和释放一个写或互斥锁。

在这次修改中，Bob 的余额查询请求就可以彼此并行地执行并且会很快地完成了。锁在更多的时间范围可用，并且存款请求也能够及时地被响应了。

~~~go
package main

import (
	"fmt"
	"sync"

	"test.go/bank"
)

func main() {
	var wg sync.WaitGroup

	for index := 0; index < 2; index++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for index := 0; index < 3; index++ {
				bank.Deposit(index)
			}
		}()

		wg.Add(1)
		go func() {
			defer wg.Done()
			for index := 0; index < 3; index++ {
				bank.WithDraw(index)
			}
		}()
	}

	wg.Wait()
	balance := bank.Balance()
	fmt.Println(balance)
}
~~~

如果使用上述测试程序，很可能每次运行的结果都不一样，除非 `bank.Deposit(100)` 让账户本身有存款。其原因是：`WithDraw` 先执行时，当 Balance 不够时，会拒绝取款。

`RLock` 只能在临界区共享变量没有任何写入操作时可用。一般来说，我们不应该假设逻辑上的只读函数、方法也不会去更新某一些变量。比如一个方法功能是访问一个变量，但它也有可能会同时去给一个内部的计数器 +1（可能是记录这个方法的访问次数）或者去更新缓存，从而让即时的调用能够更快。如果有疑惑的话，请使用互斥锁。

RWMutex 只有当获得锁的大部分 goroutine 都是读操作，而锁在竞争条件下，也就是说，goroutine 们必须等待才能获取到锁的时候，RWMutex 才是能带来好处的。**RWMutex 需要更复杂的内部记录，所以会让它比一般的无竞争锁的 mutex 慢一些**。

## 内存同步

你可能比较纠结为什么 Balance 函数需要用到互斥条件，无论是基于 channel 还是基于互斥量。毕竟和存款不一样，它只由一个简单的操作组成，所以不会碰到其它 goroutine 在其执行“期间”执行其他逻辑的风险。这里使用 mutex 有两方面的考虑。第一 Balance 不会在其他操作比如 Withdraw “中间”执行。第二（更重要的）是“同步”不仅仅是==一堆 goroutine 执行顺序的问题==，同样也会涉及到==内存的问题==。

在现代计算机中可能会有一堆**处理器**，每一个都会有其**本地缓存**（Local cache）。为了效率，对内存的写入一般会在每一个处理器中缓存，并在必要时一起 flush 到主存（内存）。这种情况下这些数据可能会以与当初 goroutine 写入顺序不同的顺序被提交到主存（内存）。**像 channel 通信或者互斥量操作这样的原语**会==使处理器将其聚集地写入 flush 并 commit，这样 goroutine 在某个时间点上的执行结果才能被其他处理器上运行的 goroutine 得到==。

考虑下面代码片段的可能输出：

~~~go
var x, y int
go func() {
    x = 1                      // A1
    fmt.Print("y:", y, " ")  // A2
}()
go func() {
    y = 1                      // B1
    fmt.Print("x:", x, " ")  // B2
}()
~~~

因为两个 goroutine 是并发执行，并且访问共享内存时也没有互斥，会有数据竞争，所以程序的运行结果没法预测的话也不要惊讶。我们可能希望它能够打赢出下面这 4 种结果中的一种，相当于几种不同的交错执行时的情况：

~~~go
y:0 x:1
x:0 y:1  // bingo
x:1 y:1
y:1 x:1
~~~

第四行可以被解释为执行顺序 A1/B1/A2/B2，或者 B1/A1/A2/B2 的执行结果。然而实际运行时还是有些情况让我们有点惊讶：

~~~go
x:0 y:0
y:0 x:0
~~~

根据所使用的编译器、CPU 或者其他很多影响因子，这两种情况也是有可能发生的。那么这两种情况要怎么解释呢？

==在一个独立的 goroutine 中，每一个语句的执行顺序是可以被保证的，也就是说 goroutine 内顺序是连贯的==。但是在不使用 channel 且不使用 mutex 这样的显式同步操作时，我们就没法保证事件在不同的 goroutine 中看到的执行顺序是一致的了。尽管 goroutine A 中一定需要观察到 x = 1 执行成功之后才会去读取 y，但它没法确保自己观察得到 goroutine B 中对 y 的写入，所以 A 还可能会打印出 y 的一个旧版的值。

尽管去理解并发的一种尝试是去将其运行理解为不同 goroutine 语句的交错执行，但看看上面的例子，这已经不是现代的编译器和 CPU 的工作方式了。因为赋值和打印指向不同的变量，编译器可能会断定两条语句的顺序不会影响执行结果，并且会交换两个语句的执行顺序。==如果两个 goroutine 在不同的 CPU 上执行==，每一个核心有自己的缓存，这样一个 goroutine 的写入对于其他 goroutine 的打印，在主存同步之前就是不可见的了。

==所有并发的问题都可以用一致的、简单的既定的模式来规避==。所以可能的话，将变量限定在 goroutine 内部；如果是多个 goroutine 都需要访问的变量，使用互斥条件来访问。

## sync.Once 惰性初始化

如果初始化成本比较大的话，那么将初始化延迟到需要的时候再去做就是一个比较好的选择。如果在程序启动的时候就去做这类初始化的话，会增加**程序的启动时间**，并且因为执行的时候可能也并不需要这些变量，所以实际上有一些浪费。让我们来看在本章早一些时候的 icons 变量：

~~~go
var icons map[string]image.Image
~~~

这个版本的 Icon 用到了**懒初始化**（Lazy Initialization）。

~~~go
func loadIcons() {
    icons = map[string]image.Image{
        "spades.png":   loadIcon("spades.png"),
        "hearts.png":   loadIcon("hearts.png"),
        "diamonds.png": loadIcon("diamonds.png"),
        "clubs.png":    loadIcon("clubs.png"),
    }
}

// NOTE: not concurrency-safe
func Icon(name string) image.Image {
    if icons == nil {
        loadIcons() // one-time initialization
    }
    return icons[name]
}
~~~

如果一个变量只被一个单独的 goroutine 所访问的话，我们可以使用上面的这种模板，但这种模板在 Icon **被并发调用时并不安全**。就像前面银行的那个 Deposit（存款）函数一样，Icon 函数也是由多个步骤组成的：首先测试 icons 是否为空，然后 load 这些 icons，之后将 icons 更新为一个非空的值。==直觉==会告诉我们最差的情况是 loadIcons 函数**被多次访问会带来数据竞争**。当第一个 goroutine 在忙着 loading 这些 icons 的时候，另一个 goroutine 进入了 Icon 函数，发现变量是 nil，然后也会调用 loadIcons 函数。

不过==这种直觉是错误的==！（我们希望从现在开始能够构建自己对并发的直觉，也就是说对并发的直觉总是不能被信任的）因为缺少显式的同步，编译器和 CPU 是可以随意地去更改访问内存的指令顺序，以任意方式，只要保证每一个 goroutine 自己的执行顺序一致。其中一种可能 loadIcons 的语句重排是下面这样。它会在填写 icons 变量的值之前先用给一个空 map 来初始化 icons 变量。

~~~go
func loadIcons() {
    icons = make(map[string]image.Image)
    icons["spades.png"] = loadIcon("spades.png")
    icons["hearts.png"] = loadIcon("hearts.png")
    icons["diamonds.png"] = loadIcon("diamonds.png")
    icons["clubs.png"] = loadIcon("clubs.png")
}
~~~

因此，一个 goroutine 在检查 icons 是非空时，也并不能就假设这个变量的初始化流程已经走完了。可能是只塞了个空 map，里面的值还没填完，也就是说填值的语句都没执行完。

最简单且正确的保证所有 goroutine 能够观察到 loadIcons 效果的方式，是用一个 mutex 来同步检测：

~~~go
var mu sync.Mutex // guards icons
var icons map[string]image.Image

func Icon(name string) image.Image {
    mu.Lock()
    defer mu.Unlock()
    if icons == nil {
        loadIcons()
    }
    return icons[name]
}
~~~

然而使用**互斥访问** icons 的==代价==就是**没有办法对该变量进行并发访问**，即使变量已经被初始化完毕且再也不会进行变动。这里我们可以引入一个允许多读的锁：

~~~go
var mu sync.RWMutex
var icons map[string]iamge.Image

func Icon(name string) image.Image {
    mu.RLock()
    if icons != nil {
        icon := icons[name]
        mu.RUnlock()
        return icon
    }
    mu.RUnlock()
    
    mu.Lock() // acquire an exclusive lock
    if icons == nil { // NOTE: must recheck for nil
        loadIcons()
    }
    icon := icons[name]
    mu.Unlock()
    return icon
}

func loadIcons() {
    icons = map[string]image.Image{
        "spades.png":   loadIcon("spades.png"),
        "hearts.png":   loadIcon("hearts.png"),
        "diamonds.png": loadIcon("diamonds.png"),
        "clubs.png":    loadIcon("clubs.png"),
    }
}
~~~

上面的代码有两个临界区。goroutine 首先会获取一个==读锁==，查询 map，然后释放锁。如果条目被找到了（一般情况下），那么会直接返回。如果没有找到，那 goroutine 会获取一个==写锁==。不释放共享锁的话，也没有任何办法来将一个==共享锁==升级为一个==互斥锁==，所以我们必须重新检查 icons 变量是否为 nil，以防止在执行这一段代码的时候，icons 变量已经**被其他 goroutine 初始化过了**。

上面的模板使我们的程序能够更好的并发，但是有一点太复杂且容易出错。幸运的是，sync 包为我们提供了一个专门的方案来解决这种**一次性初始化**的问题：`sync.Once`。概念上来讲，一次性的初始化需要一个互斥量 mutex 和一个 boolean 变量来记录初始化是不是已经完成了；互斥量用来保护 boolean 变量和客户端数据结构。Do 这个唯一的方法需要接收初始化函数作为其参数。让我们用 `sync.Once` 来简化前面的 Icon 函数：

~~~go
var loadIconOnce sync.Once

var icons map[string]image.Image

// Concurrency-safe
func Icon(name string) image.Image {
    loadIconsOnce.Do(loadIcons)
    return icons[name]
}
~~~

每一次对 Do(loadIcons) 的调用都会锁定 mutex，并会==检查 boolean 变量==。在第一次调用时，boolean 变量的值是 false，Do 会调用 loadIcons 并会将 boolean 变量设置为 true。随后的调用什么都不会做，但是 mutex 同步会保证 loadIcons 对内存（此处其实就是 icons 变量）产生的效果能够对所有 goroutine 可见。用这种方式来使用 sync.Once 的话，我们能够避免在变量被构建完成之前和其他 goroutine 共享该变量。

## 竞争条件检测

即使我们小心到不能再小心，但在并发程序中犯错还是太容易了。幸运的是，Go 的 runtime 和工具链为我们装备了一个复杂但好用的动态分析工具，**竞争检查器**（The Race Detector）。

只要在 go build，go run 或者 go test 命令后面加上 -race 的 flag，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的 test，并且会记录下每一个读或者写共享变量的 goroutine 的身份信息。另外，修改版的程序会记录下所有的同步事件，比如 go 语句，channel 操作，以及对 `(*sync.Mutex).Lock`，`(*sync.WaitGroup).Wait` 等等的调用。

完整的同步事件集合是在 `The Go Memory Model` 文档（**Go 语言内存模型**）中有说明，该文档是和语言文档放在一起的。

竞争检查器会检查这些事件，会寻找在哪一个 goroutine 中出现了这样的 case，例如其读或者写了一个共享变量，这个共享变量是被另一个 goroutine 在没有进行干预同步操作便直接写入的。这种情况也就表明了是对一个共享变量的并发访问，即数据竞争。这个工具会打印一份报告，内容包含变量身份，读取和写入的 goroutine 中活跃的函数的调用栈。这些信息在定位问题时通常很有用。

竞争检查器会报告所有的已经发生的数据竞争。然而，它只能检测到运行时的竞争条件；并不能证明之后不会发生数据竞争。所以为了使结果尽量正确，**请保证你的测试并发地覆盖到了你的包**。

由于需要额外的记录，因此构建时加了竞争检测的程序跑起来会慢一些，且需要更大的内存，即使是这样，这些代价对于很多生产环境的工作来说还是可以接受的。对于一些偶发的竞争条件来说，让竞争检查器来干活可以节省无数日夜的 debugging。

> 多少服务端 C 和 C++ 程序员为此竞折腰！

## 示例：并发的非阻塞缓存

本节中我们会做一个无阻塞的缓存，这种工具可以帮助我们来解决现实世界中并发程序出现但没有现成的库可以解决的问题。这个问题叫作**缓存（`memoizing`）函数**。也就是说，我们需要缓存函数的返回结果，这样在对函数进行调用的时候，我们就只需要一次计算，之后只要返回计算的结果就可以了。我们的解决方案会是并发安全且会避免对整个缓存加锁而导致所有操作都去争一个锁的设计。

我们将使用下面的 httpGetBody 函数作为我们需要缓存的函数的一个样例。这个函数会去进行 HTTP GET 请求并且获取 http 响应 body。对**这个函数的调用本身开销是比较大的**，所以我们尽量避免在不必要的时候反复调用。

~~~go
func httpGetBody(url string) (interface{}, error) {
    resp, err := http.Get(url)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    return ioutil.ReadAll(resp.Body)
}
~~~

最后一行稍微隐藏了一些细节，ReadAll 会返回两个结果：`[]byte` 数组和一个错误，不过这两个对象可以被赋值给 httpGetBody 的返回声明里的 `interface{}` 和 error 类型，所以我们也就可以这样返回结果并且不需要额外的工作了。我们在 httpGetBody 中选用这种返回类型是为了使其可以与缓存匹配。

下面是我们要设计的 cache 的第一个“草稿”：

~~~go
package memo

import "fmt"

// A Memo caches the results of calling a Func
type Memo struct {
	f     Func              // 调用指定的函数
	cache map[string]result // 函数调用后，存储对应的返回值
}

// Func is the type of the function to memoize
type Func func(key string) (interface{}, error)

type result struct {
	value interface{}
	err   error
}

// New is a new Memo Object
func New(f Func) *Memo {
	return &Memo{f: f, cache: make(map[string]result)}
}

// Get is run function, for get http response
// NOTE: not concurrency-safe!
func (memo *Memo) Get(key string) (interface{}, error) {
	res, ok := memo.cache[key]
	if !ok {
		// 执行 memo 对象中的 f 方法，并将返回值存储在 cache 中
		res.value, res.err = memo.f(key)
		memo.cache[key] = res
	}
	fmt.Println("key:", key)
	return res.value, res.err
}
~~~

Memo 实例会记录需要缓存的函数 f （类型为 Func），以及缓存内容（里面是一个 string 到 result 映射的 map）。每一个 result 都是简单的函数返回的值对儿——一个值和一个错误值。继续下去我们会展示一些 Memo 的变种，不过所有的例子都会遵循上面的这些方面。

下面是一个使用 Memo 的例子，对于流入的 URL 的每一个元素我们都会调用 Get，并打印调用延时以及其返回的数据大小的 log：

~~~go
package main

import (
	"fmt"
	"io/ioutil"
	"log"
	"net/http"
	"time"

	"test.go/memo"
)

func main() {
	m := memo.New(httpGetBody)
	for url := range incomingURLs() {
		start := time.Now()
		value, err := m.Get(url)
		if err != nil {
			log.Print(err)
		}
		fmt.Printf("%s, %s, %d bytes\n", url, time.Since(start), len(value.([]byte)))
	}
}

func httpGetBody(url string) (interface{}, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	return ioutil.ReadAll(resp.Body)
}

func incomingURLs() <-chan string {
	ch := make(chan string)

	go func() {
		for _, url := range []string{
			"https://www.baidu.com",
			"https://cn.bing.com",
			"https://www.amazon.cn",
			"https://www.jd.com",
		} {
			ch <- url
		}
		close(ch)
	}()

	return ch
}
~~~



## Goroutines 和线程

在前面章节中，我们说 goroutine 和操作系统的线程区别可以先忽略。尽管两者的区别实际上只是一个量的区别，但量变会引起质变的道理同样适用于 goroutine 和线程。现在正是我们来区分开两者的最佳时机。

（==动态栈==）每一个 OS 线程都有**一个固定大小的内存块（一般是 2 MB）**来做==栈==，这个栈会用来存储当前正在被调用或挂起（指在调用其它函数时）的函数的内部变量。这个固定大小的栈同时很大又很小。因为 2MB 的栈对于一个小小的 goroutine 来说是很大的内存浪费，比如对于我们用到的，一个只是用来 WaitGroup 之后关闭 channel 的 goroutine 来说。而对于 go 程序员来说，同时创建成百上千个 goroutine 是非常普遍的，如果每一个 goroutine 都需要这么大的栈的话，那这么多的 goroutine 就不太可能了。除去大小的问题之外，固定大小的栈对于更复杂或者更深层次的递归函数调用来说显然是不够的。修改固定的大小可以提升空间的利用率，允许创建更多的线程，并且可以允许更深的递归调用，不过这两者是没法同时兼备的。

相反，一个 goroutine 会以一个很小的栈开始其生命周期，一般只需要 2 KB。一个 goroutine 的栈，和操作系统线程一样，会保存其活跃或挂起的函数调用的本地变量，但是和 OS 线程不太一样的是，一个 goroutine 的栈大小并不是固定的；栈的大小会根据需要动态地伸缩。而 goroutine 的栈的最大值有 1GB，比传统的固定大小的线程栈要大得多，尽管一般情况下，大多 goroutine 都不需要这么大的栈。

（==goroutine 调度==）OS 线程会被操作系统内核调度。每几毫秒，一个邮件计时器会中断处理器，这会调用一个叫作 scheduler 的内核函数。这个函数会挂起当前执行的线程并将它的寄存器内容保存到内存中，检查线程列表并决定下一次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行线程。因为操作系统线程是被内核所调度，所以从一个线程向另一个“移动”需要完整的上下文切换，也就是说，保存一个用户线程的状态到内存，恢复另一个线程的状态到寄存器，然后更新调度器的数据结构。这几步操作很慢，因为其局部性很差需要几次内存访问，并且会增加运行的 CPU 周期。

Go 的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如 m:n 调度，因为其会在 n 个操作系统线程上多工调度 m 个 goroutine。Go 调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的 Go 程序中的 goroutine。

和操作系统的线程调度不同的是，Go 调度器并不是用一个硬件定时器，而是被 Go 语言“建筑”本身进行调度的。例如当一个 goroutine 调用了 time.Sleep，或者被 channel 调用或者 mutex 操作阻塞时，调度器会使其进入休眠并开始执行另一个 goroutine，直到时机到了再去唤醒第一个 goroutine。因为这种调度方式不需要进入内核的上下文，所以重新调度一个 goroutine 比调度一个线程代价要低得多。

（==GOMAXPROCS==）Go 调度器使用了一个叫做 GOMAXPROCS 的变量来决定会有多少个操作系统的线程同时执行 Go 代码。其默认的值是运行机器上的 CPU 核数，所以在一个有 8 个核心的机器上时，调度器一次会在 8 个 OS 线程上去调度 Go 代码。（GOMAXPROCS 是前面说的 m:n 调度中的 n）。在休眠中的或者在通信中被阻塞的 goroutine 是不需要一个对应的线程来做调度的。在 I/O 中或系统调用中或调用非 Go 语言函数时，是需要一个对应的操作系统线程的，但是 GOMAXPROCS 并不需要将这几种情况计算在内。

你可以用 GOMAXPROCS 的环境变量来显示地控制这个参数，或者也可以在运行时用 runtime.GOMAXPROCS 函数来修改它。我们在下面的小程序中会看到 GOMAXPROCS 的效果，这个程序会无限打印 0 和 1。

~~~go
for {
    go fmt.Print(0)
    fmt.Print(1)
}

$ GOMAXPROCS=1 go run hacker-cliché.go
111111111111111111110000000000000000000011111...

$ GOMAXPROCS=2 go run hacker-cliché.go
010101010101010101011001100101011010010100110...
~~~

在第一次执行时，最多同时只能有一个 goroutine 被执行。初始情况下只有 main goroutine 被执行，所以会打印很多 1。过了一段时间后，Go 调度器会将其置为休眠，并唤醒另一个 goroutine，这时候就开始打印很多 0 了，在打印的时候，goroutine 是被调度到操作系统线程上的。在第二次执行时，我们使用了两个操作系统线程，所以两个 goroutine 可以一起被执行，以同样的频率交替打印 0 和 1。我们必须强调的是 goroutine 的调度是受很多因子影响的，而 runtime 也是在不断地发展演进的，所以这里的你实际得到的结果可能会因为版本的不同而与我们运行的结果有所不同。

（==goroutine 没有 ID 号==）在大多数支持多线程的操作系统和程序语言中，当前的线程都有一个独特的身份（ID），并且这个身份信息可以以一个普通值的形式被很容易地获取到，典型的可以是一个 integer 或者指针值。这种情况下我们做一个抽象化的 thread-local storage（线程本地存储，多线程编程中不希望其他线程访问的内容）就很容易，只需要以线程的 id 作为 key 的一个 map 就可以解决问题，每一个线程以其 id 就能从中获取到值，且和其他线程互不冲突。

goroutine 没有可以被程序员获取到的身份（id）的概念。这一点是设计上故意而为之，由于 thread-local-storage 总是会被滥用。比如说，一个 web server 是用一种支持 tls 的语言实现的，而非常普遍的是很多函数会去寻找 HTTP 请求的信息，这代表它们就是去其存储层（这个存储层有可能是 tls）查找的。这就像是那些过分依赖全局变量的程序一样，会导致一种非健康的“距离外行为”，在这种行为下，一个函数的行为可能并不仅由自己的参数所决定，而是由其所运行的线程所决定。因此，如果线程本身的身份会改变——比如一些 worker 线程之类的——那么函数的行为就会变得神秘莫测。

Go 鼓励更为简单的模式，这种模式下的参数（外部显示参数和内部显示参数，tls 中的内容算是“外部”隐式参数）对函数的影响都是显式的。这样不仅使程序变得更易读，而且会让我们自由地向一些给定的函数分配子任务时不用担心其身份信息影响行为。

你能在应该已经明白了写一个 Go 程序所需要的所有语言特性信息。在后面两章节中，我们会回顾一些之前的实例和工具，支持我们**写出更大规模的程序**：**如何将一个工程组织成一系列的包，如何获取，构建，测试，性能测试，剖析，写文档，并且将这些包分享出去**！